{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpDTJeyyD_bA",
        "outputId": "b31e31dc-e307-4f8a-dda1-79237fcfb69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: diffusers==0.3.0 in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (0.31.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers==0.3.0) (11.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.1->diffusers==0.3.0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.1->diffusers==0.3.0) (4.13.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.4->diffusers==0.3.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.4->diffusers==0.3.0) (1.3.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.3.0) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.3.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.3.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers==0.3.0) (2025.4.26)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.4->diffusers==0.3.0) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers==0.3.0 transformers ftfy opencv-python ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bupi6_vEPv7U"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Union, Tuple, List, Callable, Dict\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch.nn.functional as nnf\n",
        "import numpy as np\n",
        "import abc\n",
        "import ptp_utils\n",
        "import seq_aligner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410,
          "referenced_widgets": [
            "8fff357619424239a86fc1041f6edf0d",
            "af45e585a8bd43489c849ac8d5e4d17f",
            "86e6b3399fe44cd1b2f1b4062ba97644",
            "502e302897dd468d85356840021cc4e8",
            "17b24cf304764a5591082c95ce261148",
            "61766ad3ecba461593d1831eee3a9ada",
            "fe9b921b1a744d3ca5eab73c73202ebf",
            "fc41f96022764b7eb76f27f4cf56d1f9",
            "f09cc9c516fd460abc03c82e59cef496",
            "e9912759ceb948da89bb0b44138951e9",
            "0a7ebb1ae8e3426099150579c4836e7c"
          ]
        },
        "id": "IriB9KIoE-x4",
        "outputId": "4a265b40-72af-4f49-a6d2-5ce68b3843ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fff357619424239a86fc1041f6edf0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 33 files:   0%|          | 0/33 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "attribute name must be string, not 'NoneType'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b980e4f58866>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMAX_NUM_WORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m77\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mldm_stable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStableDiffusionPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CompVis/stable-diffusion-v1-4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMY_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldm_stable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                         \u001b[0mload_method_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportable_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mload_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_method_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mloading_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: attribute name must be string, not 'NoneType'"
          ]
        }
      ],
      "source": [
        "MY_TOKEN = '<add_yours_here>'\n",
        "LOW_RESOURCE = False\n",
        "NUM_DIFFUSION_STEPS = 50\n",
        "GUIDANCE_SCALE = 7.5\n",
        "MAX_NUM_WORDS = 77\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "ldm_stable = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=MY_TOKEN).to(device)\n",
        "tokenizer = ldm_stable.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPuSQSnrGoqh"
      },
      "outputs": [],
      "source": [
        "class LocalBlend:\n",
        "\n",
        "    def __call__(self, x_t, attention_store):\n",
        "        k = 1\n",
        "        maps = attention_store[\"down_cross\"][2:4] + attention_store[\"up_cross\"][:3]\n",
        "        maps = [item.reshape(self.alpha_layers.shape[0], -1, 1, 16, 16, MAX_NUM_WORDS) for item in maps]\n",
        "        maps = torch.cat(maps, dim=1)\n",
        "        maps = (maps * self.alpha_layers).sum(-1).mean(1)\n",
        "        mask = nnf.max_pool2d(maps, (k * 2 + 1, k * 2 +1), (1, 1), padding=(k, k))\n",
        "        mask = nnf.interpolate(mask, size=(x_t.shape[2:]))\n",
        "        mask = mask / mask.max(2, keepdims=True)[0].max(3, keepdims=True)[0]\n",
        "        mask = mask.gt(self.threshold)\n",
        "        mask = (mask[:1] + mask[1:]).float()\n",
        "        x_t = x_t[:1] + mask * (x_t - x_t[:1])\n",
        "        return x_t\n",
        "\n",
        "    def __init__(self, prompts: List[str], words: [List[List[str]]], threshold=.3):\n",
        "        alpha_layers = torch.zeros(len(prompts),  1, 1, 1, 1, MAX_NUM_WORDS)\n",
        "        for i, (prompt, words_) in enumerate(zip(prompts, words)):\n",
        "            if type(words_) is str:\n",
        "                words_ = [words_]\n",
        "            for word in words_:\n",
        "                ind = ptp_utils.get_word_inds(prompt, word, tokenizer)\n",
        "                alpha_layers[i, :, :, :, :, ind] = 1\n",
        "        self.alpha_layers = alpha_layers.to(device)\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "class AttentionControl(abc.ABC):\n",
        "\n",
        "    def step_callback(self, x_t):\n",
        "        return x_t\n",
        "\n",
        "    def between_steps(self):\n",
        "        return\n",
        "\n",
        "    @property\n",
        "    def num_uncond_att_layers(self):\n",
        "        return self.num_att_layers if LOW_RESOURCE else 0\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def forward (self, attn, is_cross: bool, place_in_unet: str):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __call__(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        if self.cur_att_layer >= self.num_uncond_att_layers:\n",
        "            if LOW_RESOURCE:\n",
        "                attn = self.forward(attn, is_cross, place_in_unet)\n",
        "            else:\n",
        "                h = attn.shape[0]\n",
        "                attn[h // 2:] = self.forward(attn[h // 2:], is_cross, place_in_unet)\n",
        "        self.cur_att_layer += 1\n",
        "        if self.cur_att_layer == self.num_att_layers + self.num_uncond_att_layers:\n",
        "            self.cur_att_layer = 0\n",
        "            self.cur_step += 1\n",
        "            self.between_steps()\n",
        "        return attn\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_step = 0\n",
        "        self.cur_att_layer = 0\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cur_step = 0\n",
        "        self.num_att_layers = -1\n",
        "        self.cur_att_layer = 0\n",
        "\n",
        "class EmptyControl(AttentionControl):\n",
        "\n",
        "    def forward (self, attn, is_cross: bool, place_in_unet: str):\n",
        "        return attn\n",
        "\n",
        "\n",
        "class AttentionStore(AttentionControl):\n",
        "\n",
        "    @staticmethod\n",
        "    def get_empty_store():\n",
        "        return {\"down_cross\": [], \"mid_cross\": [], \"up_cross\": [],\n",
        "                \"down_self\": [],  \"mid_self\": [],  \"up_self\": []}\n",
        "\n",
        "    def forward(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        key = f\"{place_in_unet}_{'cross' if is_cross else 'self'}\"\n",
        "        if attn.shape[1] <= 32 ** 2:  # avoid memory overhead\n",
        "            self.step_store[key].append(attn)\n",
        "        return attn\n",
        "\n",
        "    def between_steps(self):\n",
        "        if len(self.attention_store) == 0:\n",
        "            self.attention_store = self.step_store\n",
        "        else:\n",
        "            for key in self.attention_store:\n",
        "                for i in range(len(self.attention_store[key])):\n",
        "                    self.attention_store[key][i] += self.step_store[key][i]\n",
        "        self.step_store = self.get_empty_store()\n",
        "\n",
        "    def get_average_attention(self):\n",
        "        average_attention = {key: [item / self.cur_step for item in self.attention_store[key]] for key in self.attention_store}\n",
        "        return average_attention\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        super(AttentionStore, self).reset()\n",
        "        self.step_store = self.get_empty_store()\n",
        "        self.attention_store = {}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AttentionStore, self).__init__()\n",
        "        self.step_store = self.get_empty_store()\n",
        "        self.attention_store = {}\n",
        "\n",
        "\n",
        "class AttentionControlEdit(AttentionStore, abc.ABC):\n",
        "\n",
        "    def step_callback(self, x_t):\n",
        "        if self.local_blend is not None:\n",
        "            x_t = self.local_blend(x_t, self.attention_store)\n",
        "        return x_t\n",
        "\n",
        "    def replace_self_attention(self, attn_base, att_replace):\n",
        "        if att_replace.shape[2] <= 16 ** 2:\n",
        "            return attn_base.unsqueeze(0).expand(att_replace.shape[0], *attn_base.shape)\n",
        "        else:\n",
        "            return att_replace\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        super(AttentionControlEdit, self).forward(attn, is_cross, place_in_unet)\n",
        "        if is_cross or (self.num_self_replace[0] <= self.cur_step < self.num_self_replace[1]):\n",
        "            h = attn.shape[0] // (self.batch_size)\n",
        "            attn = attn.reshape(self.batch_size, h, *attn.shape[1:])\n",
        "            attn_base, attn_repalce = attn[0], attn[1:]\n",
        "            if is_cross:\n",
        "                alpha_words = self.cross_replace_alpha[self.cur_step]\n",
        "                attn_repalce_new = self.replace_cross_attention(attn_base, attn_repalce) * alpha_words + (1 - alpha_words) * attn_repalce\n",
        "                attn[1:] = attn_repalce_new\n",
        "            else:\n",
        "                attn[1:] = self.replace_self_attention(attn_base, attn_repalce)\n",
        "            attn = attn.reshape(self.batch_size * h, *attn.shape[2:])\n",
        "        return attn\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int,\n",
        "                 cross_replace_steps: Union[float, Tuple[float, float], Dict[str, Tuple[float, float]]],\n",
        "                 self_replace_steps: Union[float, Tuple[float, float]],\n",
        "                 local_blend: Optional[LocalBlend]):\n",
        "        super(AttentionControlEdit, self).__init__()\n",
        "        self.batch_size = len(prompts)\n",
        "        self.cross_replace_alpha = ptp_utils.get_time_words_attention_alpha(prompts, num_steps, cross_replace_steps, tokenizer).to(device)\n",
        "        if type(self_replace_steps) is float:\n",
        "            self_replace_steps = 0, self_replace_steps\n",
        "        self.num_self_replace = int(num_steps * self_replace_steps[0]), int(num_steps * self_replace_steps[1])\n",
        "        self.local_blend = local_blend\n",
        "\n",
        "class AttentionReplace(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        return torch.einsum('hpw,bwn->bhpn', attn_base, self.mapper)\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float,\n",
        "                 local_blend: Optional[LocalBlend] = None):\n",
        "        super(AttentionReplace, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.mapper = seq_aligner.get_replacement_mapper(prompts, tokenizer).to(device)\n",
        "\n",
        "\n",
        "class AttentionRefine(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        attn_base_replace = attn_base[:, :, self.mapper].permute(2, 0, 1, 3)\n",
        "        attn_replace = attn_base_replace * self.alphas + att_replace * (1 - self.alphas)\n",
        "        return attn_replace\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float,\n",
        "                 local_blend: Optional[LocalBlend] = None):\n",
        "        super(AttentionRefine, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.mapper, alphas = seq_aligner.get_refinement_mapper(prompts, tokenizer)\n",
        "        self.mapper, alphas = self.mapper.to(device), alphas.to(device)\n",
        "        self.alphas = alphas.reshape(alphas.shape[0], 1, 1, alphas.shape[1])\n",
        "\n",
        "\n",
        "class AttentionReweight(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        if self.prev_controller is not None:\n",
        "            attn_base = self.prev_controller.replace_cross_attention(attn_base, att_replace)\n",
        "        attn_replace = attn_base[None, :, :, :] * self.equalizer[:, None, None, :]\n",
        "        return attn_replace\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float, equalizer,\n",
        "                local_blend: Optional[LocalBlend] = None, controller: Optional[AttentionControlEdit] = None):\n",
        "        super(AttentionReweight, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.equalizer = equalizer.to(device)\n",
        "        self.prev_controller = controller\n",
        "\n",
        "\n",
        "def get_equalizer(text: str, word_select: Union[int, Tuple[int, ...]], values: Union[List[float],\n",
        "                  Tuple[float, ...]]):\n",
        "    if type(word_select) is int or type(word_select) is str:\n",
        "        word_select = (word_select,)\n",
        "    equalizer = torch.ones(len(values), 77)\n",
        "    values = torch.tensor(values, dtype=torch.float32)\n",
        "    for word in word_select:\n",
        "        inds = ptp_utils.get_word_inds(text, word, tokenizer)\n",
        "        equalizer[:, inds] = values\n",
        "    return equalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLO2ITsoGqoL"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def aggregate_attention(attention_store: AttentionStore, res: int, from_where: List[str], is_cross: bool, select: int):\n",
        "    out = []\n",
        "    attention_maps = attention_store.get_average_attention()\n",
        "    print(list(attention_maps.keys()))\n",
        "    num_pixels = res ** 2\n",
        "    for location in from_where:\n",
        "        for item in attention_maps[f\"{location}_{'cross' if is_cross else 'self'}\"]:\n",
        "            if item.shape[1] == num_pixels:\n",
        "                cross_maps = item.reshape(len(prompts), -1, res, res, item.shape[-1])[select]\n",
        "                out.append(cross_maps)\n",
        "    out = torch.cat(out, dim=0)\n",
        "    out = out.sum(0) / out.shape[0]\n",
        "    return out.cpu()\n",
        "\n",
        "\n",
        "def show_cross_attention(attention_store: AttentionStore, res: int, from_where: List[str], select: int = 0):\n",
        "    tokens = tokenizer.encode(prompts[select])\n",
        "    decoder = tokenizer.decode\n",
        "    attention_maps = aggregate_attention(attention_store, res, from_where, True, select)\n",
        "    images = []\n",
        "    for i in range(len(tokens)):\n",
        "        image = attention_maps[:, :, i]\n",
        "        image = 255 * image / image.max()\n",
        "        image = image.unsqueeze(-1).expand(*image.shape, 3)\n",
        "        image = image.numpy().astype(np.uint8)\n",
        "        image = np.array(Image.fromarray(image).resize((256, 256)))\n",
        "        image = ptp_utils.text_under_image(image, decoder(int(tokens[i])))\n",
        "        images.append(image)\n",
        "    ptp_utils.view_images(np.stack(images, axis=0))\n",
        "\n",
        "\n",
        "def show_self_attention_comp(attention_store: AttentionStore, res: int, from_where: List[str],\n",
        "                        max_com=10, select: int = 0):\n",
        "    attention_maps = aggregate_attention(attention_store, res, from_where, False, select).numpy().reshape((res ** 2, res ** 2))\n",
        "    u, s, vh = np.linalg.svd(attention_maps - np.mean(attention_maps, axis=1, keepdims=True))\n",
        "    images = []\n",
        "    for i in range(max_com):\n",
        "        image = vh[i].reshape(res, res)\n",
        "        image = image - image.min()\n",
        "        image = 255 * image / image.max()\n",
        "        image = np.repeat(np.expand_dims(image, axis=2), 3, axis=2).astype(np.uint8)\n",
        "        image = Image.fromarray(image).resize((256, 256))\n",
        "        image = np.array(image)\n",
        "        images.append(image)\n",
        "    ptp_utils.view_images(np.concatenate(images, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6h-7Y4hKbS0"
      },
      "outputs": [],
      "source": [
        "def run_and_display(prompts, controller, latent=None, run_baseline=False, generator=None):\n",
        "    if run_baseline:\n",
        "        print(\"w.o. prompt-to-prompt\")\n",
        "        images, latent = run_and_display(prompts, EmptyControl(), latent=latent, run_baseline=False, generator=generator)\n",
        "        print(\"with prompt-to-prompt\")\n",
        "    images, x_t = ptp_utils.text2image_ldm_stable(ldm_stable, prompts, controller, latent=latent, num_inference_steps=NUM_DIFFUSION_STEPS, guidance_scale=GUIDANCE_SCALE, generator=generator, low_resource=LOW_RESOURCE)\n",
        "    ptp_utils.view_images(images)\n",
        "    return images, x_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FF8cy89GuHP"
      },
      "outputs": [],
      "source": [
        "g_cpu = torch.Generator().manual_seed(8888)\n",
        "prompts = [\"A painting of a squirrel eating a burger\"]\n",
        "controller = AttentionStore()\n",
        "image, x_t = run_and_display(prompts, controller, latent=None, run_baseline=False, generator=g_cpu)\n",
        "show_cross_attention(controller, res=16, from_where=(\"up\", \"down\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3yVReVlIbcq"
      },
      "outputs": [],
      "source": [
        "prompts = [\"A painting of a squirrel eating a burger\",\n",
        "           \"A painting of a lion eating a burger\"]\n",
        "\n",
        "controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8, self_replace_steps=0.4)\n",
        "_ = run_and_display(prompts, controller, latent=x_t, run_baseline=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqt06ru-MBij"
      },
      "outputs": [],
      "source": [
        "print(list(controller.attention_store.keys()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a7ebb1ae8e3426099150579c4836e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17b24cf304764a5591082c95ce261148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502e302897dd468d85356840021cc4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9912759ceb948da89bb0b44138951e9",
            "placeholder": "​",
            "style": "IPY_MODEL_0a7ebb1ae8e3426099150579c4836e7c",
            "value": " 33/33 [00:00&lt;00:00, 1619.27it/s]"
          }
        },
        "61766ad3ecba461593d1831eee3a9ada": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e6b3399fe44cd1b2f1b4062ba97644": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc41f96022764b7eb76f27f4cf56d1f9",
            "max": 33,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f09cc9c516fd460abc03c82e59cef496",
            "value": 33
          }
        },
        "8fff357619424239a86fc1041f6edf0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af45e585a8bd43489c849ac8d5e4d17f",
              "IPY_MODEL_86e6b3399fe44cd1b2f1b4062ba97644",
              "IPY_MODEL_502e302897dd468d85356840021cc4e8"
            ],
            "layout": "IPY_MODEL_17b24cf304764a5591082c95ce261148"
          }
        },
        "af45e585a8bd43489c849ac8d5e4d17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61766ad3ecba461593d1831eee3a9ada",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9b921b1a744d3ca5eab73c73202ebf",
            "value": "Fetching 33 files: 100%"
          }
        },
        "e9912759ceb948da89bb0b44138951e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09cc9c516fd460abc03c82e59cef496": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc41f96022764b7eb76f27f4cf56d1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9b921b1a744d3ca5eab73c73202ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
