{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "fstMGFcV52H_",
        "outputId": "56f95776-dcf8-4a4f-c6dc-50835486a271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nblip2_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\\nblip2_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\").to(device)\\n'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install transformers pillow pandas tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "#from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
        "\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def ensure_direct_image_url(url):\n",
        "    \"\"\"\n",
        "    For imgur: convert non-direct to i.imgur.com/ID.jpg.\n",
        "    All other URLs: return as-is.\n",
        "    \"\"\"\n",
        "    if \"imgur.com\" in url and not re.search(r'\\.(jpg|jpeg|png|gif|bmp|webp|tiff)$', url, re.IGNORECASE):\n",
        "        match = re.search(r'imgur\\.com/(?:gallery/|a/)?([^/?#]+)', url)\n",
        "        if match:\n",
        "            img_id = match.group(1)\n",
        "            return f\"https://i.imgur.com/{img_id}.jpg\"\n",
        "        match = re.search(r'imgur\\.com/([^/?#]+)', url)\n",
        "        if match:\n",
        "            img_id = match.group(1)\n",
        "            return f\"https://i.imgur.com/{img_id}.jpg\"\n",
        "    return url\n",
        "\n",
        "#your logic\n",
        "def smart_download_image(url, save_path):\n",
        "    if \"dropbox.com\" in url:\n",
        "        url = url.replace(\"?dl=0\", \"\")\n",
        "        if \"?raw=1\" not in url:\n",
        "            if \"?\" in url:\n",
        "                url += \"&raw=1\"\n",
        "            else:\n",
        "                url += \"?raw=1\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
        "        \"Accept\": \"image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8\",\n",
        "        \"Referer\": url,\n",
        "        \"Accept-Encoding\": \"identity\",\n",
        "        \"Connection\": \"keep-alive\"\n",
        "    }\n",
        "    try:\n",
        "        resp = requests.get(url, headers=headers, timeout=30)\n",
        "        if resp.status_code == 200 and resp.headers.get('content-type', '').startswith(\"image\"):\n",
        "            with open(save_path, \"wb\") as f:\n",
        "                f.write(resp.content)\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Failed (status {resp.status_code}, type {resp.headers.get('content-type', '')}) for {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Download error for {url}: {e}\")\n",
        "    return False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
        "\"\"\"\n",
        "blip2_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
        "blip2_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\").to(device)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMX7zXfv_Av2",
        "outputId": "ae3d933c-f566-42c5-9d9d-bacc0972879d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n"
          ]
        }
      ],
      "source": [
        "def generate_blip_caption(image_path, blip_processor, blip_model):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        inputs = blip_processor(images=image, return_tensors=\"pt\").to(blip_model.device)\n",
        "        output = blip_model.generate(**inputs, max_length=50, num_beams=11,length_penalty=1.7, repetition_penalty=1.4,early_stopping=True, do_sample=False)\n",
        "        caption = blip_processor.decode(output[0], skip_special_tokens=True)\n",
        "        return caption\n",
        "    except Exception as e:\n",
        "        print(f\"BLIP failed for {image_path}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\"\"\"\n",
        "def generate_blip2_flan_caption(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    prompt = \"Describe this image in extreme detail:\"\n",
        "    inputs = blip2_processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
        "    output = blip2_model.generate(**inputs, max_new_tokens=35)\n",
        "    caption = blip2_processor.decode(output[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "\"\"\"\n",
        "df = pd.read_csv(\"RealEdit_train_split_urls.csv\")\n",
        "\n",
        "output = []\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "N = 10\n",
        "for i, row in tqdm(df.iterrows(), total=min(len(df), N)):\n",
        "    if i >= N: break\n",
        "    orig_url = str(row[\"input_url\"])\n",
        "    img_url = ensure_direct_image_url(orig_url)\n",
        "    img_name = row[\"input_image_name\"]\n",
        "    local_path = f\"images/{img_name}\"\n",
        "    caption = \"\"\n",
        "    if smart_download_image(img_url, local_path):\n",
        "        caption = generate_blip_caption(local_path, blip_processor, blip_model)\n",
        "        #caption = generate_blip2_flan_caption(local_path)\n",
        "    output.append({\n",
        "        \"input_image_name\": img_name,\n",
        "        \"input_url\": orig_url,\n",
        "        \"download_url\": img_url,\n",
        "        \"download_success\": os.path.exists(local_path) and os.path.getsize(local_path) > 0,\n",
        "        \"caption\": caption\n",
        "    })\n",
        "\n",
        "ff = pd.DataFrame(output)\n",
        "ff.to_csv(\"captions.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
