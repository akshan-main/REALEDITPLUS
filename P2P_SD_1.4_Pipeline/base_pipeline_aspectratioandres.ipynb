{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPSc-vdGbMdJ"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nr0fB56lbMdK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256,expandable_segments:True\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdUPeDYabMdL"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uESt5ZJJPuY8",
        "outputId": "0cf1ea0d-8729-4df5-ae50-bdd99984f301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface in /usr/local/lib/python3.11/dist-packages (0.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "20S8H7gZbMdL",
        "outputId": "41599404-544a-432a-9487-fdbd8f9d9ce4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom diffusers import StableDiffusionPipeline, DDIMScheduler\\n\\npipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\\nfor module in pipe.text_encoder.modules():\\n    if hasattr(module, \"inplace\") and module.inplace:\\n        module.inplace = False\\n\\npipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\\npipe.enable_attention_slicing()\\ntry:\\n    pipe.enable_xformers_memory_efficient_attention()\\nexcept Exception:\\n    pass\\n'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, requests, json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import openai\n",
        "openai.api_key = 'your openai key'\n",
        "\n",
        "\n",
        "from transformers import CLIPModel, CLIPProcessor, AutoTokenizer, AutoModel\n",
        "'''\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(\"cuda\")\n",
        "for module in pipe.text_encoder.modules():\n",
        "    if hasattr(module, \"inplace\") and module.inplace:\n",
        "        module.inplace = False\n",
        "\n",
        "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_attention_slicing()\n",
        "try:\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "except Exception:\n",
        "    pass\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O14Nq_BbMdM",
        "outputId": "4470a83d-f3e5-403d-a2ea-2dfa3accc074"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [00:00<00:01,  4.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping 3v1cvp.jpg: download failed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  7.23it/s]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def ensure_direct_image_url(url):\n",
        "    \"\"\"Convert Imgur/Dropbox URLs to direct image links if needed.\"\"\"\n",
        "    if \"imgur.com\" in url and not re.search(r'\\.(jpg|jpeg|png|bmp)$', url):\n",
        "        m = re.search(r'imgur\\.com/(?:gallery/|a/)?([^.?&]+)', url)\n",
        "        if m: return f\"https://i.imgur.com/{m.group(1)}.jpg\"\n",
        "    return url\n",
        "\n",
        "def smart_download_image(url, save_path):\n",
        "    \"\"\"Download an image with user-agent header, handling Dropbox links.\"\"\"\n",
        "    if \"dropbox.com\" in url:\n",
        "        url = url.replace(\"?dl=0\", \"\")\n",
        "        if \"?raw=1\" not in url:\n",
        "            url += \"&raw=1\" if \"?\" not in url else \"&raw=1\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\", \"Accept-Encoding\": \"identity\"}\n",
        "    try:\n",
        "        resp = requests.get(url, headers=headers, timeout=30)\n",
        "        if resp.status_code == 200 and resp.headers.get('content-type','').startswith(\"image\"):\n",
        "            with open(save_path, \"wb\") as f: f.write(resp.content)\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"Download error for {url}: {e}\")\n",
        "    return False\n",
        "\n",
        "df = pd.read_csv(\"RealEdit_train_split_urls.csv\")\n",
        "os.makedirs(\"originals\", exist_ok=True)\n",
        "\n",
        "N = 10\n",
        "image_info = []\n",
        "for i, row in tqdm(df.iterrows(), total=min(len(df), N)):\n",
        "    if i >= N: break\n",
        "    fname = row[\"input_image_name\"]\n",
        "    url = ensure_direct_image_url(str(row[\"input_url\"]))\n",
        "    save_path = f\"originals/{fname}\"\n",
        "    if smart_download_image(url, save_path):\n",
        "        image_info.append((fname, url, row.get(\"subreddit\",\"\"), str(row.get(\"title\",\"\")), str(row.get(\"selftext\",\"\"))))\n",
        "    else:\n",
        "        print(f\"Skipping {fname}: download failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjubYrkNbMdM"
      },
      "outputs": [],
      "source": [
        "from transformers import CLIPTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwQw6J62bMdM"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import OpenAI\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhRcw82KbMdM",
        "outputId": "d4f5b631-919b-4914-b821-254fb71dba97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping 3vn0dc.jpeg: file missing or too small.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "def truncate_caption_safely(caption, max_tokens=77):\n",
        "    sentences = re.split(r'(?<=[.!?]) +', caption.strip())\n",
        "\n",
        "    current_text = \"\"\n",
        "    for sentence in sentences:\n",
        "        proposed_text = (current_text + \" \" + sentence).strip()\n",
        "        token_ids = tokenizer(proposed_text, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]\n",
        "        if len(token_ids) > max_tokens:\n",
        "            break\n",
        "        current_text = proposed_text\n",
        "\n",
        "    return current_text\n",
        "\n",
        "\n",
        "captions = []\n",
        "client = OpenAI(api_key=openai.api_key)\n",
        "\n",
        "image_dir = \"originals\"\n",
        "image_files = [f for f in os.listdir(image_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))][:N]\n",
        "captions = []\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "    if not os.path.exists(image_path) or os.path.getsize(image_path) < 1024:\n",
        "        print(f\"Skipping {image_file}: file missing or too small.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as img_file:\n",
        "            image_bytes = img_file.read()\n",
        "            base64_img = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": \"Describe the image in full detail, but limit your response to under 50 words. Focus on what's visually clear. Avoid exaggeration or hallucination. Do not include information that is not clearly visible in the image.\"},\n",
        "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_img}\"}}\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=77\n",
        "        )\n",
        "\n",
        "        caption = response.choices[0].message.content.strip()\n",
        "        caption = truncate_caption_safely(caption)\n",
        "        captions.append((image_file, caption))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"{image_file}, Error: {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aojf2FAbMdM",
        "outputId": "605daa43-c25e-4db5-a486-736b19ddbcf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|    | Image       | Caption                                                                                                                                                                                                                                                              |\n",
            "|----|-------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "|  0 | 3vtoea.jpeg | A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a small bottle and cylinder, are on the table. The setting is open, with concrete flooring.                                             |\n",
            "|  1 | 3vo49o.jpg  | A sepia-toned photograph shows a group of people in front of an old wooden house, surrounded by trees. Five individuals, including a seated woman in a hammock, and a dog are visible. The setting is a grassy yard, with a traditional rustic appearance.           |\n",
            "|  2 | 3vtbmy.jpg  | A couple stands on the beach; the man is shirtless, and the woman wears a light top and shorts. They embrace near the shoreline. The ocean waves are visible in the background with a couple of people farther out in the water.                                     |\n",
            "|  3 | 3vupca.jpeg | A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop. |\n",
            "|  4 | 3v2ru0.jpeg | A vintage black and white photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The image is textured and cracked, suggesting age.                                                                |\n",
            "|  5 | 3vo9iy.jpg  | A group of eleven people is posed outdoors. Most are dressed formally, with several wearing dark suits and others in dresses. They stand in front of a wooden structure with foliage. The image is black and white.                                                  |\n",
            "|  6 | 3vqxg7.jpeg | A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. The background is blurred, suggesting an outdoor setting. The image captures a joyful moment between the two.                         |\n",
            "|  7 | 3vg97p.jpg  | A person in a uniform walks between rows of sandbags stacked alongside buildings with slanted roofs. Dark barrels are positioned at the ends of the sandbag rows. The lighting appears bright, creating a washed-out effect.                                         |\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "df = pd.DataFrame(captions, columns=[\"Image\", \"Caption\"])\n",
        "print(tabulate(df, headers=\"keys\", tablefmt=\"github\", showindex=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVU3cU0sbMdM"
      },
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0cuhZlHbMdN"
      },
      "outputs": [],
      "source": [
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFJ0g99cbMdN",
        "outputId": "6aabf5c2-4f3f-46c2-9d9f-10c281e56b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating edits for '3vtoea.jpeg' with caption: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a small bottle and cylinder, are on the table. The setting is open, with concrete flooring.\n",
            " 1. INSTR: Add a cat sitting next to the child | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. A cat sits next to the child. Various items on the table.\n",
            " 2. INSTR: Change the setting to a lush garden | CAPTION: A man and a child are at a long, outdoor table in a lush garden, with the child aiming a rifle, assisted by the man. Various items on the table.\n",
            " 3. INSTR: Make the child wear a cowboy hat | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. The child wears a cowboy hat. Various items on the table.\n",
            " 4. INSTR: Remove the small bottle from the table | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a cylinder, are on the table. The setting is open.\n",
            " 5. INSTR: Increase the brightness of the image | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a small bottle and cylinder, are on the table. The setting is open.\n",
            " 6. INSTR: Change the man's clothing to a Hawaiian shirt | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man wearing a Hawaiian shirt. Various items on the table.\n",
            " 7. INSTR: Make the table covered in colorful flowers | CAPTION: A man and a child are at a long, outdoor table covered in colorful flowers, with the child aiming a rifle, assisted by the man. Various items on the table.\n",
            " 8. INSTR: Add a flock of birds flying in the background | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a small bottle and cylinder, are on the table. A flock of birds flies in the background.\n",
            " 9. INSTR: Make the concrete flooring look like a sandy beach | CAPTION: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a small bottle and cylinder, are on the table. The setting looks like a sandy beach.\n",
            " 10. INSTR: Remove the rifle from the child's hands | CAPTION: A man and a child are at a long, outdoor table, with the child assisted by the man. Various items, including a small bottle and cylinder, are on the table. The setting is open, with concrete flooring.\n",
            "\n",
            "Generating edits for '3vo49o.jpg' with caption: A sepia-toned photograph shows a group of people in front of an old wooden house, surrounded by trees. Five individuals, including a seated woman in a hammock, and a dog are visible. The setting is a grassy yard, with a traditional rustic appearance.\n",
            " 1. INSTR: Add a cat next to the dog | CAPTION: In front of an old wooden house, a group of people and pets gather. A seated woman in a hammock, a dog, and a cat now visible.\n",
            " 2. INSTR: Change the sepia tone to black and white | CAPTION: A black and white photograph captures a group of people in front of an old wooden house, surrounded by trees. A seated woman in a hammock and others are visible.\n",
            " 3. INSTR: Make the trees in the background taller | CAPTION: In front of an old wooden house, taller trees now surround a group of people. A seated woman in a hammock and others are visible.\n",
            " 4. INSTR: Replace the grassy yard with a sandy beach | CAPTION: In front of an old wooden house on a sandy beach, a group of people and a dog gather. A seated woman in a hammock is among them.\n",
            " 5. INSTR: Add a vintage bicycle leaning against the house | CAPTION: A vintage bicycle now leans against the old wooden house, as a group of people and a dog gather in the yard. A seated woman in a hammock is visible.\n",
            " 6. INSTR: Change the rustic appearance to modern | CAPTION: In front of a modern house, a group of people and a dog gather. A seated woman in a hammock is among them, in a contemporary setting.\n",
            " 7. INSTR: Remove two people and keep only the seated woman and the dog | CAPTION: In front of an old wooden house, a seated woman in a hammock and a dog remain. The setting includes trees and a grassy yard.\n",
            " 8. INSTR: Make the house look abandoned with broken windows | CAPTION: An abandoned house with broken windows stands in the background as a group of people and a dog gather in the yard. A seated woman in a hammock is visible.\n",
            " 9. INSTR: Change the hammock to a swing hanging from a tree | CAPTION: A swing now hangs from a tree in the yard, where a group of people and a dog gather. The setting includes an old wooden house and trees.\n",
            " 10. INSTR: Add colorful flowers to the grassy yard | CAPTION: A group of people and a dog gather in the yard, surrounded by colorful flowers. An old wooden house and trees complete the picturesque setting.\n",
            "\n",
            "Generating edits for '3vtbmy.jpg' with caption: A couple stands on the beach; the man is shirtless, and the woman wears a light top and shorts. They embrace near the shoreline. The ocean waves are visible in the background with a couple of people farther out in the water.\n",
            " 1. INSTR: Add a beach umbrella behind the couple | CAPTION: A couple stands on the beach near a colorful beach umbrella; the man shirtless, woman in a light top and shorts, embracing near the shoreline.\n",
            " 2. INSTR: Change the woman's outfit to a floral dress | CAPTION: A couple stands on the beach; the man shirtless, the woman in a floral dress, embracing near the shoreline with ocean waves in the background.\n",
            " 3. INSTR: Remove the people farther out in the water | CAPTION: A couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with ocean waves visible in the background.\n",
            " 4. INSTR: Add a beach ball on the sand | CAPTION: A couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with a beach ball on the sand.\n",
            " 5. INSTR: Make the ocean waves more dramatic | CAPTION: A couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with dramatic ocean waves in the background.\n",
            " 6. INSTR: Change the sky to a sunset setting | CAPTION: A couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with a sunset setting in the background.\n",
            " 7. INSTR: Add seagulls flying in the sky | CAPTION: A couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with seagulls flying in the sky.\n",
            " 8. INSTR: Change the sand to a tropical white color | CAPTION: A couple stands on the white tropical sand beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline.\n",
            " 9. INSTR: Make the couple appear more relaxed | CAPTION: A relaxed couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with ocean waves visible in the background.\n",
            " 10. INSTR: Add a palm tree in the background | CAPTION: A couple stands on the beach; the man shirtless, woman in a light top and shorts, embracing near the shoreline with a palm tree in the background.\n",
            "\n",
            "Generating edits for '3vupca.jpeg' with caption: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop.\n",
            " 1. INSTR: Change the woman's dress to a flowery pattern | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a flowery pattern. The setting is a simple studio backdrop.\n",
            " 2. INSTR: Add a bouquet of flowers in the woman's hand | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row holds a bouquet of flowers. The setting is a simple studio backdrop.\n",
            " 3. INSTR: Remove the bow ties from two of the men | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, one with a bow tie, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop.\n",
            " 4. INSTR: Change the background to a scenic outdoor landscape | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a scenic outdoor landscape.\n",
            " 5. INSTR: Add a playful dog next to the sitting individuals | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. A playful dog is next to the sitting individuals.\n",
            " 6. INSTR: Make the studio backdrop look like a beach scene | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a beach scene.\n",
            " 7. INSTR: Change the lighting to create a dramatic shadow effect | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop with dramatic shadow effects.\n",
            " 8. INSTR: Make the standing individuals wear casual attire | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear casual outfits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop.\n",
            " 9. INSTR: Add a vintage filter to give a nostalgic feel | CAPTION: A sepia-toned family portrait shows seven individuals, three sitting and four standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop with a vintage nostalgic filter.\n",
            " 10. INSTR: Change the position of one sitting individual to stand | CAPTION: A sepia-toned family portrait shows seven individuals, two sitting and five standing, all in formal attire. The men wear suits, some with bow ties, and the woman in the back row wears a dress with a checkered pattern. The setting is a simple studio backdrop.\n",
            "\n",
            "Generating edits for '3v2ru0.jpeg' with caption: A vintage black and white photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The image is textured and cracked, suggesting age.\n",
            " 1. INSTR: Add a cat sitting next to the child | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. A cat sits next to the child.\n",
            " 2. INSTR: Convert the image to sepia tone | CAPTION: A vintage sepia-toned photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The image is textured and cracked.\n",
            " 3. INSTR: Enhance the cracks on the image for a dramatic effect | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The image is heavily cracked for a dramatic effect.\n",
            " 4. INSTR: Change the woman's dress color to red | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a red dress. The image is textured and cracked, suggesting age.\n",
            " 5. INSTR: Add a bicycle in the background behind the man | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. A bicycle is in the background behind the man.\n",
            " 6. INSTR: Make the man and woman smile | CAPTION: A vintage B&W photo shows a smiling man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The image is textured and cracked, suggesting age.\n",
            " 7. INSTR: Change the child's hairstyle to long hair | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The child has long hair. The image is textured and cracked.\n",
            " 8. INSTR: Remove the cracks from the image for a cleaner look | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The image is clean without cracks.\n",
            " 9. INSTR: Add a bird perched on the man's shoulder | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. A bird is perched on the man's shoulder.\n",
            " 10. INSTR: Change the background to a beach setting | CAPTION: A vintage B&W photo shows a man and woman seated closely with a child in front. The man wears glasses, the woman wears a floral dress. The background is a beach setting.\n",
            "\n",
            "Generating edits for '3vo9iy.jpg' with caption: A group of eleven people is posed outdoors. Most are dressed formally, with several wearing dark suits and others in dresses. They stand in front of a wooden structure with foliage. The image is black and white.\n",
            " 1. INSTR: Add a colorful rainbow in the background | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. A colorful rainbow decorates the background.\n",
            " 2. INSTR: Replace the formal attire with beachwear | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed in beachwear, adding a casual vibe.\n",
            " 3. INSTR: Insert a vintage car behind the group | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. A vintage car is parked behind them, adding a retro touch.\n",
            " 4. INSTR: Remove all foliage from the background | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure. Most are dressed formally, with several wearing dark suits and others in dresses. The image is black and white.\n",
            " 5. INSTR: Change the image to sepia tone | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed formally, with several wearing dark suits and others in dresses. The image has a sepia tone.\n",
            " 6. INSTR: Add a hot air balloon in the sky | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed formally, with several wearing dark suits and others in dresses. A hot air balloon floats in the sky.\n",
            " 7. INSTR: Make one person wear a cowboy hat | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed formally, with several wearing dark suits and others in dresses. One person stands out wearing a cowboy hat.\n",
            " 8. INSTR: Change the time of day to dusk | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed formally, with several wearing dark suits and others in dresses. The image depicts dusk setting in.\n",
            " 9. INSTR: Add a flock of birds flying overhead | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed formally, with several wearing dark suits and others in dresses. A flock of birds flies overhead.\n",
            " 10. INSTR: Make the image appear as a painting | CAPTION: A group of eleven people is posed outdoors in front of a wooden structure with foliage. Most are dressed formally, with several wearing dark suits and others in dresses. The image has a painterly effect.\n",
            "\n",
            "Generating edits for '3vqxg7.jpeg' with caption: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. The background is blurred, suggesting an outdoor setting. The image captures a joyful moment between the two.\n",
            " 1. INSTR: Add colorful balloons floating in the background | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. Colorful balloons float in the background, adding a festive touch.\n",
            " 2. INSTR: Place a picnic blanket on the ground under them | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. A picnic blanket is placed on the ground under them, creating a cozy atmosphere.\n",
            " 3. INSTR: Change the man's outfit to a casual t-shirt and shorts | CAPTION: A black-and-white photo shows a man holding a laughing child in the air. The child wears striped clothes and sneakers. The man now wears a casual t-shirt and shorts, giving a more relaxed vibe.\n",
            " 4. INSTR: Add a gentle breeze blowing the child's hair | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. A gentle breeze blows the child's hair, adding movement to the image.\n",
            " 5. INSTR: Change the blurred background to a sunny beach scene | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. The background is now a sunny beach scene, enhancing the joyful moment.\n",
            " 6. INSTR: Make the child wear a superhero cape | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child now wears a superhero cape over striped clothes and sneakers, adding a playful element.\n",
            " 7. INSTR: Add a rainbow arcing across the sky | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. A rainbow arcs across the sky, bringing a magical touch to the scene.\n",
            " 8. INSTR: Change the man's expression to a surprised look | CAPTION: A black-and-white photo shows a man holding a laughing child in the air. The child wears striped clothes and sneakers. The man now has a surprised look on his face, adding an unexpected twist.\n",
            " 9. INSTR: Place a small dog peeking out from behind the man | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. A small dog peeks out from behind the man, adding a cute element.\n",
            " 10. INSTR: Add a kite flying in the sky above them | CAPTION: A black-and-white photo shows a smiling man holding a laughing child in the air. The child wears striped clothes and sneakers. A kite flies in the sky above them, adding a sense of freedom.\n",
            "\n",
            "Generating edits for '3vg97p.jpg' with caption: A person in a uniform walks between rows of sandbags stacked alongside buildings with slanted roofs. Dark barrels are positioned at the ends of the sandbag rows. The lighting appears bright, creating a washed-out effect.\n",
            " 1. INSTR: Add a military helicopter flying overhead | CAPTION: A person in a uniform walks between rows of sandbags with a military helicopter flying overhead.\n",
            " 2. INSTR: Change the lighting to a dramatic sunset | CAPTION: A person in a uniform walks between rows of sandbags under a dramatic sunset sky.\n",
            " 3. INSTR: Replace sandbags with tall cacti | CAPTION: A person in a uniform walks between rows of tall cacti stacked alongside buildings with slanted roofs.\n",
            " 4. INSTR: Add a group of pigeons perched on the sandbags | CAPTION: A person in a uniform walks between rows of sandbags with a group of pigeons perched on them.\n",
            " 5. INSTR: Change the uniform to a futuristic spacesuit | CAPTION: A person in a futuristic spacesuit walks between rows of sandbags stacked alongside buildings with slanted roofs.\n",
            " 6. INSTR: Remove the dark barrels from the ends of the sandbag rows | CAPTION: A person in a uniform walks between rows of sandbags stacked alongside buildings with slanted roofs.\n",
            " 7. INSTR: Add a stray cat walking by the sandbag rows | CAPTION: A person in a uniform walks between rows of sandbags with a stray cat walking by.\n",
            " 8. INSTR: Change the sky to a starry night | CAPTION: A person in a uniform walks between rows of sandbags under a starry night sky.\n",
            " 9. INSTR: Make the buildings in the background look abandoned | CAPTION: A person in a uniform walks between rows of sandbags stacked alongside abandoned buildings with slanted roofs.\n",
            " 10. INSTR: Add a vintage bicycle leaning against a sandbag | CAPTION: A person in a uniform walks between rows of sandbags with a vintage bicycle leaning against one of them.\n"
          ]
        }
      ],
      "source": [
        "all_edits = {}\n",
        "cap_and_edits = {}\n",
        "for (fname, cap) in captions:\n",
        "    print(f\"\\nGenerating edits for '{fname}' with caption: {cap}\")\n",
        "    prompt = (\n",
        "    \"You are simulating real user editing behavior for a dataset of image edits.\\n\"\n",
        "    \"Given a description of an image, imagine how actual users would ask to modify it. \"\n",
        "    \"These edits should be creative, realistic, and specific — things a person might type into an AI editor, like:\\n\"\n",
        "    \"- 'Add a dog sitting near the woman'\\n\"\n",
        "    \"- 'Make the sunset more vibrant'\\n\"\n",
        "    \"- 'Change the man’s outfit to a business suit'\\n\"\n",
        "    \"- 'Remove the second person from the left'\\n\"\n",
        "    \"- 'Make the child look older'\\n\"\n",
        "    \"Each edit should involve a meaningful visual change to the image, not just generic filters like 'increase contrast'.\\n\"\n",
        "    \"\\n\"\n",
        "    \"For each instruction, generate a matching edited image caption that describes the image *after* the edit.\\n\"\n",
        "    \"Each 'edited_caption' must be **under 77 tokens**, even after tokenization (not just word count).\\n\"\n",
        "    \"Avoid repetitions. The 10 edits must be diverse (e.g. subject, background, object-level, style).\\n\"\n",
        "    \"\\n\"\n",
        "    \"Output a JSON array of 10 items, where each item is an object with two fields:\\n\"\n",
        "    \"- 'instruction': the user's edit request\\n\"\n",
        "    \"- 'edited_caption': the caption for the image after applying that edit\\n\"\n",
        "    \"Do not include any explanation. Return only the JSON array.\\n\\n\"\n",
        "    f\"Image Description: \\\"{cap}\\\"\"\n",
        "    )\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.8\n",
        "        )\n",
        "        gpt_output = response.choices[0].message.content\n",
        "        start = gpt_output.find('[')\n",
        "        end = gpt_output.rfind(']') + 1\n",
        "        edits = json.loads(gpt_output[start:end])\n",
        "    except Exception as e:\n",
        "        print(f\"GPT API call failed for {fname}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if not isinstance(edits, list) or len(edits) != 10:\n",
        "        print(f\"Unexpected format for {fname}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    filtered_edits = []\n",
        "    for item in edits:\n",
        "        tok_len = len(enc.encode(item[\"edited_caption\"]))\n",
        "        if tok_len < 77:\n",
        "            filtered_edits.append(item)\n",
        "        else:\n",
        "            print(f\"Skipping overlong caption (len={tok_len}) for '{fname}': {item['edited_caption']}\")\n",
        "\n",
        "    if len(filtered_edits) < 10:\n",
        "        print(f\"Only {len(filtered_edits)} valid edits (under 77 tokens) for {fname}.\")\n",
        "\n",
        "    all_edits[fname] = filtered_edits\n",
        "\n",
        "    cap_and_edits[fname] = []\n",
        "    cap_and_edits[fname].append(cap)\n",
        "    cap_and_edits[fname].append([])\n",
        "\n",
        "    for idx, item in enumerate(filtered_edits, 1):\n",
        "        print(f\" {idx}. INSTR: {item['instruction']} | CAPTION: {item['edited_caption']}\")\n",
        "        cap_and_edits[fname][1].append((item['instruction'], item['edited_caption']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5If-Lz7nbMdN"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Union, Tuple, List, Callable, Dict\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "#from diffusers import StableDiffusion3Pipeline\n",
        "#from diffusers import DiffusionPipeline\n",
        "import torch.nn.functional as nnf\n",
        "import numpy as np\n",
        "import abc\n",
        "import ptp_utils\n",
        "import seq_aligner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "4b37efa16725442aa949962c1afe5524",
            "c69674a607734d0186f19a6aa8ffc034",
            "328393d5de84442dbece09ae627e1be1",
            "fa5cdd80763d4f5a869b0f1722c0f8ac",
            "035a2bcd3ffe43ecb8679ef2d06db2d4",
            "c76ffc21d3174ca4bf872b2b9ac90453",
            "b0787b4e557049a1bb959405b88a9a28",
            "00850f16d0934d63a3b988d3d261dec2",
            "d1f38831492d4f77bcc39cf16a4cb878",
            "bf681b0268894ee3ab9d6ca33e5bd442",
            "f6a23a134d644989a3156f7159ed305e",
            "8b377f944b334f96bec7aa619849d964",
            "8054c7299f67463287f7b517ba46fb20",
            "b195d25c62024da39f4587ba11e933a2",
            "01beb93790ea4a49ae2253da5bd6aaad",
            "28ecb263b8664bfe9f1988d3aa352082",
            "09a99cc507a04385bdd2285cf3afe72e",
            "f801fb50a0e04e6f9b646141bb333e39",
            "7092d722fd684f859ec7c25c04ecd84a",
            "f735a1a9e86d4d659bfedeb53fe16569",
            "bad0574ba2104a9b99efc97fb94ab604",
            "2f2871256f634e2aa8850b582504aa25"
          ]
        },
        "id": "GWxqFtWzbMdN",
        "outputId": "6c5c7f02-447d-4922-a4bc-1f92fab3fa7c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b37efa16725442aa949962c1afe5524",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Keyword arguments {'use_auth_token': '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'} are not expected by StableDiffusionPipeline and will be ignored.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b377f944b334f96bec7aa619849d964",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MY_TOKEN = '#your huggingface token'\n",
        "LOW_RESOURCE = False\n",
        "NUM_DIFFUSION_STEPS = 50\n",
        "GUIDANCE_SCALE = 7.5\n",
        "MAX_NUM_WORDS = 77\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "ldm_stable = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=MY_TOKEN).to(device)\n",
        "#ldm_stable = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large\")\n",
        "#ldm_stable = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large\", torch_dtype=torch.bfloat16)\n",
        "#ldm_stable = StableDiffusion3Pipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large-turbo\", torch_dtype=torch.bfloat16)\n",
        "#ldm_stable = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-3.5-large-turbo\")\n",
        "#ldm_stable = ldm_stable.to(device)\n",
        "tokenizer = ldm_stable.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2tNYYWJbMdN"
      },
      "outputs": [],
      "source": [
        "class LocalBlend:\n",
        "\n",
        "    def __call__(self, x_t, attention_store):\n",
        "        k = 1\n",
        "        maps = attention_store[\"down_cross\"][2:4] + attention_store[\"up_cross\"][:3]\n",
        "        maps = [item.reshape(self.alpha_layers.shape[0], -1, 1, 16, 16, MAX_NUM_WORDS) for item in maps]\n",
        "        maps = torch.cat(maps, dim=1)\n",
        "        maps = (maps * self.alpha_layers).sum(-1).mean(1)\n",
        "        mask = nnf.max_pool2d(maps, (k * 2 + 1, k * 2 +1), (1, 1), padding=(k, k))\n",
        "        mask = nnf.interpolate(mask, size=(x_t.shape[2:]))\n",
        "        mask = mask / mask.max(2, keepdims=True)[0].max(3, keepdims=True)[0]\n",
        "        mask = mask.gt(self.threshold)\n",
        "        mask = (mask[:1] + mask[1:]).float()\n",
        "        x_t = x_t[:1] + mask * (x_t - x_t[:1])\n",
        "        return x_t\n",
        "\n",
        "    def __init__(self, prompts: List[str], words: List[List[str]], threshold=.3):\n",
        "        alpha_layers = torch.zeros(len(prompts),  1, 1, 1, 1, MAX_NUM_WORDS)\n",
        "        for i, (prompt, words_) in enumerate(zip(prompts, words)):\n",
        "            if type(words_) is str:\n",
        "                words_ = [words_]\n",
        "            for word in words_:\n",
        "                ind = ptp_utils.get_word_inds(prompt, word, tokenizer)\n",
        "                alpha_layers[i, :, :, :, :, ind] = 1\n",
        "        self.alpha_layers = alpha_layers.to(device)\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "class AttentionControl(abc.ABC):\n",
        "\n",
        "    def step_callback(self, x_t):\n",
        "        return x_t\n",
        "\n",
        "    def between_steps(self):\n",
        "        return\n",
        "\n",
        "    @property\n",
        "    def num_uncond_att_layers(self):\n",
        "        return self.num_att_layers if LOW_RESOURCE else 0\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def forward (self, attn, is_cross: bool, place_in_unet: str):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __call__(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        if self.cur_att_layer >= self.num_uncond_att_layers:\n",
        "            if LOW_RESOURCE:\n",
        "                attn = self.forward(attn, is_cross, place_in_unet)\n",
        "            else:\n",
        "                h = attn.shape[0]\n",
        "                attn[h // 2:] = self.forward(attn[h // 2:], is_cross, place_in_unet)\n",
        "        self.cur_att_layer += 1\n",
        "        if self.cur_att_layer == self.num_att_layers + self.num_uncond_att_layers:\n",
        "            self.cur_att_layer = 0\n",
        "            self.cur_step += 1\n",
        "            self.between_steps()\n",
        "        return attn\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_step = 0\n",
        "        self.cur_att_layer = 0\n",
        "\n",
        "    def __init__(self):\n",
        "        self.cur_step = 0\n",
        "        self.num_att_layers = -1\n",
        "        self.cur_att_layer = 0\n",
        "\n",
        "class EmptyControl(AttentionControl):\n",
        "\n",
        "    def forward (self, attn, is_cross: bool, place_in_unet: str):\n",
        "        return attn\n",
        "\n",
        "\n",
        "class AttentionStore(AttentionControl):\n",
        "\n",
        "    @staticmethod\n",
        "    def get_empty_store():\n",
        "        return {\"down_cross\": [], \"mid_cross\": [], \"up_cross\": [],\n",
        "                \"down_self\": [],  \"mid_self\": [],  \"up_self\": []}\n",
        "\n",
        "    def forward(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        key = f\"{place_in_unet}_{'cross' if is_cross else 'self'}\"\n",
        "        if attn.shape[1] <= 32 ** 2:  # avoid memory overhead\n",
        "            self.step_store[key].append(attn)\n",
        "        return attn\n",
        "\n",
        "    def between_steps(self):\n",
        "        if len(self.attention_store) == 0:\n",
        "            self.attention_store = self.step_store\n",
        "        else:\n",
        "            for key in self.attention_store:\n",
        "                for i in range(len(self.attention_store[key])):\n",
        "                    self.attention_store[key][i] += self.step_store[key][i]\n",
        "        self.step_store = self.get_empty_store()\n",
        "\n",
        "    def get_average_attention(self):\n",
        "        average_attention = {key: [item / self.cur_step for item in self.attention_store[key]] for key in self.attention_store}\n",
        "        return average_attention\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        super(AttentionStore, self).reset()\n",
        "        self.step_store = self.get_empty_store()\n",
        "        self.attention_store = {}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AttentionStore, self).__init__()\n",
        "        self.step_store = self.get_empty_store()\n",
        "        self.attention_store = {}\n",
        "\n",
        "\n",
        "class AttentionControlEdit(AttentionStore, abc.ABC):\n",
        "\n",
        "    def step_callback(self, x_t):\n",
        "        if self.local_blend is not None:\n",
        "            x_t = self.local_blend(x_t, self.attention_store)\n",
        "        return x_t\n",
        "\n",
        "    def replace_self_attention(self, attn_base, att_replace):\n",
        "        if att_replace.shape[2] <= 16 ** 2:\n",
        "            return attn_base.unsqueeze(0).expand(att_replace.shape[0], *attn_base.shape)\n",
        "        else:\n",
        "            return att_replace\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, attn, is_cross: bool, place_in_unet: str):\n",
        "        super(AttentionControlEdit, self).forward(attn, is_cross, place_in_unet)\n",
        "        if is_cross or (self.num_self_replace[0] <= self.cur_step < self.num_self_replace[1]):\n",
        "            h = attn.shape[0] // (self.batch_size)\n",
        "            attn = attn.reshape(self.batch_size, h, *attn.shape[1:])\n",
        "            attn_base, attn_repalce = attn[0], attn[1:]\n",
        "            if is_cross:\n",
        "                alpha_words = self.cross_replace_alpha[self.cur_step]\n",
        "                attn_repalce_new = self.replace_cross_attention(attn_base, attn_repalce) * alpha_words + (1 - alpha_words) * attn_repalce\n",
        "                attn[1:] = attn_repalce_new\n",
        "            else:\n",
        "                attn[1:] = self.replace_self_attention(attn_base, attn_repalce)\n",
        "            attn = attn.reshape(self.batch_size * h, *attn.shape[2:])\n",
        "        return attn\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int,\n",
        "                 cross_replace_steps: Union[float, Tuple[float, float], Dict[str, Tuple[float, float]]],\n",
        "                 self_replace_steps: Union[float, Tuple[float, float]],\n",
        "                 local_blend: Optional[LocalBlend]):\n",
        "        super(AttentionControlEdit, self).__init__()\n",
        "        self.batch_size = len(prompts)\n",
        "        self.cross_replace_alpha = ptp_utils.get_time_words_attention_alpha(prompts, num_steps, cross_replace_steps, tokenizer).to(device)\n",
        "        if type(self_replace_steps) is float:\n",
        "            self_replace_steps = 0, self_replace_steps\n",
        "        self.num_self_replace = int(num_steps * self_replace_steps[0]), int(num_steps * self_replace_steps[1])\n",
        "        self.local_blend = local_blend\n",
        "\n",
        "class AttentionReplace(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        return torch.einsum('hpw,bwn->bhpn', attn_base, self.mapper)\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float,\n",
        "                 local_blend: Optional[LocalBlend] = None):\n",
        "        super(AttentionReplace, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.mapper = seq_aligner.get_replacement_mapper(prompts, tokenizer).to(device)\n",
        "\n",
        "\n",
        "class AttentionRefine(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        attn_base_replace = attn_base[:, :, self.mapper].permute(2, 0, 1, 3)\n",
        "        attn_replace = attn_base_replace * self.alphas + att_replace * (1 - self.alphas)\n",
        "        return attn_replace\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float,\n",
        "                 local_blend: Optional[LocalBlend] = None):\n",
        "        super(AttentionRefine, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.mapper, alphas = seq_aligner.get_refinement_mapper(prompts, tokenizer)\n",
        "        self.mapper, alphas = self.mapper.to(device), alphas.to(device)\n",
        "        self.alphas = alphas.reshape(alphas.shape[0], 1, 1, alphas.shape[1])\n",
        "\n",
        "\n",
        "class AttentionReweight(AttentionControlEdit):\n",
        "\n",
        "    def replace_cross_attention(self, attn_base, att_replace):\n",
        "        if self.prev_controller is not None:\n",
        "            attn_base = self.prev_controller.replace_cross_attention(attn_base, att_replace)\n",
        "        attn_replace = attn_base[None, :, :, :] * self.equalizer[:, None, None, :]\n",
        "        return attn_replace\n",
        "\n",
        "    def __init__(self, prompts, num_steps: int, cross_replace_steps: float, self_replace_steps: float, equalizer,\n",
        "                local_blend: Optional[LocalBlend] = None, controller: Optional[AttentionControlEdit] = None):\n",
        "        super(AttentionReweight, self).__init__(prompts, num_steps, cross_replace_steps, self_replace_steps, local_blend)\n",
        "        self.equalizer = equalizer.to(device)\n",
        "        self.prev_controller = controller\n",
        "\n",
        "\n",
        "def get_equalizer(text: str, word_select: Union[int, Tuple[int, ...]], values: Union[List[float],\n",
        "                  Tuple[float, ...]]):\n",
        "    if type(word_select) is int or type(word_select) is str:\n",
        "        word_select = (word_select,)\n",
        "    equalizer = torch.ones(len(values), 77)\n",
        "    values = torch.tensor(values, dtype=torch.float32)\n",
        "    for word in word_select:\n",
        "        inds = ptp_utils.get_word_inds(text, word, tokenizer)\n",
        "        equalizer[:, inds] = values\n",
        "    return equalizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SasBjeHhbMdO"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def aggregate_attention(attention_store: AttentionStore, res: int, from_where: List[str], is_cross: bool, select: int):\n",
        "    out = []\n",
        "    attention_maps = attention_store.get_average_attention()\n",
        "    num_pixels = res ** 2\n",
        "    for location in from_where:\n",
        "        for item in attention_maps[f\"{location}_{'cross' if is_cross else 'self'}\"]:\n",
        "            if item.shape[1] == num_pixels:\n",
        "                cross_maps = item.reshape(len(prompts), -1, res, res, item.shape[-1])[select]\n",
        "                out.append(cross_maps)\n",
        "    out = torch.cat(out, dim=0)\n",
        "    out = out.sum(0) / out.shape[0]\n",
        "    return out.cpu()\n",
        "\n",
        "\n",
        "def show_cross_attention(attention_store: AttentionStore, res: int, from_where: List[str], select: int = 0):\n",
        "    tokens = tokenizer.encode(prompts[select])\n",
        "    decoder = tokenizer.decode\n",
        "    attention_maps = aggregate_attention(attention_store, res, from_where, True, select)\n",
        "    images = []\n",
        "    for i in range(len(tokens)):\n",
        "        image = attention_maps[:, :, i]\n",
        "        image = 255 * image / image.max()\n",
        "        image = image.unsqueeze(-1).expand(*image.shape, 3)\n",
        "        image = image.numpy().astype(np.uint8)\n",
        "        image = np.array(Image.fromarray(image).resize((256, 256)))\n",
        "        image = ptp_utils.text_under_image(image, decoder(int(tokens[i])))\n",
        "        images.append(image)\n",
        "    ptp_utils.view_images(np.stack(images, axis=0))\n",
        "\n",
        "\n",
        "def show_self_attention_comp(attention_store: AttentionStore, res: int, from_where: List[str],\n",
        "                        max_com=10, select: int = 0):\n",
        "    attention_maps = aggregate_attention(attention_store, res, from_where, False, select).numpy().reshape((res ** 2, res ** 2))\n",
        "    u, s, vh = np.linalg.svd(attention_maps - np.mean(attention_maps, axis=1, keepdims=True))\n",
        "    images = []\n",
        "    for i in range(max_com):\n",
        "        image = vh[i].reshape(res, res)\n",
        "        image = image - image.min()\n",
        "        image = 255 * image / image.max()\n",
        "        image = np.repeat(np.expand_dims(image, axis=2), 3, axis=2).astype(np.uint8)\n",
        "        image = Image.fromarray(image).resize((256, 256))\n",
        "        image = np.array(image)\n",
        "        images.append(image)\n",
        "    ptp_utils.view_images(np.concatenate(images, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQJ5-N0jbMdO"
      },
      "outputs": [],
      "source": [
        "def run_and_display(prompts, controller, latent=None, run_baseline=False, generator=None):\n",
        "    if run_baseline:\n",
        "        print(\"w.o. prompt-to-prompt\")\n",
        "        images, latent = run_and_display(prompts, EmptyControl(), latent=latent, run_baseline=False, generator=generator)\n",
        "        print(\"with prompt-to-prompt\")\n",
        "    images, x_t = ptp_utils.text2image_ldm_stable(ldm_stable, prompts, controller, latent=latent, num_inference_steps=NUM_DIFFUSION_STEPS, guidance_scale=GUIDANCE_SCALE, generator=generator, low_resource=LOW_RESOURCE)\n",
        "    #ptp_utils.view_images(images)\n",
        "    return images, x_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "43b4cdda4a8443efa2260e29dc579a5d",
            "9010bbb959f349268d7c0bf012293641",
            "e0292ea84ff5485d921eef6cd387fb5b",
            "e5c5bb0f21624ea084a6b987d9e4bd23",
            "899aadafb12348aea5bb83094786763a",
            "de9263865e504ee286bbe49d28a07df8",
            "87fc453ff88d47b59f8d99a312e79543",
            "fa55f2eb11fa49cda1ba1f39a3698800",
            "adb0e3d1b91647e3be1ecdfd539cb678",
            "092dab7c69b040a5a97656f000e7bcdc",
            "2bbdb71798b74e9ca5dfab251df05a74",
            "289ed9e039334a63a29578d54e408b51",
            "c40b2bcb15d348ea8f904bf6d19d0b1b",
            "e5c23ce424bb48e8a30bd93f4c109524",
            "f8f3a6cce09a4f88bf0a543e11276610",
            "4fe65fa5c87146eb891bb981700433bf",
            "087339a206cc4a23a2da89908e8cb717",
            "f311c13fb8d7486c97a7d10c11834a87",
            "41156a3a61fc4e92952f224bb7c566ab",
            "4dc5f9ff6d924d76806b7b559d058a97",
            "f4e88ec388b646fc9d9cca18179873b5",
            "3fa086f7175d4bd19ba459643dc23354"
          ]
        },
        "id": "AKHh4AwlTDkY",
        "outputId": "5c01db49-ddea-4362-adc0-697fed6b6289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OG Caption: A man and a child are at a long, outdoor table, with the child aiming a rifle, assisted by the man. Various items, including a small bottle and cylinder, are on the table. The setting is open, with concrete flooring.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/ptp_utils.py:90: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  (1, model.unet.in_channels, height // 8, width // 8),\n",
            "/content/ptp_utils.py:93: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  latents = latent.expand(batch_size,  model.unet.in_channels, height // 8, width // 8).to(model.device)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43b4cdda4a8443efa2260e29dc579a5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "289ed9e039334a63a29578d54e408b51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\"\"\"\n",
        "#print(cap_and_edits)\n",
        "#print(\"OG Caption: \" + str(cap_and_edits))\n",
        "save_root = \"dataset\"\n",
        "os.makedirs(save_root, exist_ok=True)\n",
        "\n",
        "sample_idx = 0\n",
        "\n",
        "for _, captions in cap_and_edits.items():\n",
        "    og_cap = captions[0]\n",
        "    edited_caps = captions[1]\n",
        "\n",
        "    print(\"OG Caption: \" + og_cap)\n",
        "\n",
        "    g_cpu = torch.Generator().manual_seed(8888)\n",
        "    prompts = [og_cap]\n",
        "    controller = AttentionStore()\n",
        "    original_image, x_t = run_and_display(prompts, controller, latent=None, run_baseline=False, generator=g_cpu)\n",
        "    original_pil = Image.fromarray(original_image[0])\n",
        "\n",
        "\n",
        "    for instr, ec in edited_caps:\n",
        "        #print(\"INSTRUCTION:\" + str(instr))\n",
        "        #print(\"EDITED Caption:\" + str(ec))\n",
        "        #os.makedirs(\"first_img_edits\", exist_ok=True)\n",
        "        #img = Image.fromarray(image[0])  # image[0] = (H, W, C), dtype=uint8\n",
        "        prompts = [og_cap, ec]\n",
        "\n",
        "        #controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.8, self_replace_steps=0.4)\n",
        "        #_ = run_and_display(prompts, controller, latent=x_t, run_baseline=True)\n",
        "\n",
        "\n",
        "        controller = AttentionRefine(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.5, self_replace_steps=.2)\n",
        "        edited_image, _ = run_and_display(prompts, controller, latent=x_t)\n",
        "        edited_pil = Image.fromarray(edited_image[0])\n",
        "\n",
        "        sample_dir = os.path.join(save_root, f\"sample_{sample_idx:04d}\")\n",
        "        os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "        original_pil.save(os.path.join(sample_dir, \"original.png\"))\n",
        "        edited_pil.save(os.path.join(sample_dir, \"edited.png\"))\n",
        "\n",
        "        with open(os.path.join(sample_dir, \"original_caption.txt\"), 'w') as f:\n",
        "            f.write(og_cap)\n",
        "\n",
        "        with open(os.path.join(sample_dir, \"edited_caption.txt\"), 'w') as f:\n",
        "            f.write(ec)\n",
        "\n",
        "        with open(os.path.join(sample_dir, \"instruction.txt\"), 'w') as f:\n",
        "            f.write(instr)\n",
        "\n",
        "        sample_idx += 1\n",
        "\n",
        "        #comment out to run on all edit instructions\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "    # comment out to run on all input captions\n",
        "    break\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172,
          "referenced_widgets": [
            "c92a2647c77d4733ba099128efa9e02a",
            "cb31eb583b7e43578eec2bf9ab5d935f",
            "418b345cec1349e7b8427d3456974f31",
            "2bf12cefd733492ca68b89f908a95f10",
            "24ac4a27c846462c81394845960543da",
            "af70071ba040433ca790cd15c38f3395",
            "92050fd669e0434097133cb4906c1e0d",
            "b207d215705d45318a49da033a733642",
            "3d9cd571c6654ac289cccdfe13fcf1b5",
            "c425438c366d48c4988d019cb41e9afc",
            "e4132c0b523d442e841e763838f76115",
            "781b5664894f48d694f3c181000290d9",
            "b5f85218f7c147dc99fd3accedaeb087",
            "f5b26d9383fd455db669afca8c4a318f",
            "77704e8ba56048edb8fe7496dd8f8c11",
            "81b08039964948c6a61eb85c85a4005d",
            "574c7bab5a724c15b21e0ec71b4b452b",
            "c7b9f24006b849feb718ae4bb810e0a6",
            "031afc1c05dd4080898d402d97748c0d",
            "615f7c39bc554ac29cc1988b808284a4",
            "ac4a4ad095424c25a98862cfb99ae420",
            "a336b9cbd16a4b399edc4708cd0a898a"
          ]
        },
        "id": "YkeIzGvTDx_v",
        "outputId": "f1fdc23f-5e3c-4b51-943b-f9efff92ccbd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/ptp_utils.py:90: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  (1, model.unet.in_channels, height // 8, width // 8),\n",
            "/content/ptp_utils.py:93: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.\n",
            "  latents = latent.expand(batch_size,  model.unet.in_channels, height // 8, width // 8).to(model.device)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c92a2647c77d4733ba099128efa9e02a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "781b5664894f48d694f3c181000290d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/51 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.transforms.functional import resize\n",
        "\n",
        "target_resolution = (1024, 1024)\n",
        "\n",
        "save_root = \"dataset\"\n",
        "os.makedirs(save_root, exist_ok=True)\n",
        "\n",
        "ASPECT_RATIOS = [(4, 3), (16, 9), (1, 1), (3, 2), (5, 4)]\n",
        "sample_idx = 0\n",
        "\n",
        "for _, captions in cap_and_edits.items():\n",
        "    og_cap = captions[0]\n",
        "    edited_caps = captions[1]\n",
        "\n",
        "    aspect_ratio = random.choice(ASPECT_RATIOS)\n",
        "    base_res = 512\n",
        "    w_ratio, h_ratio = aspect_ratio\n",
        "    new_w, new_h = base_res, int((h_ratio / w_ratio) * base_res)\n",
        "\n",
        "    g_cpu = torch.Generator().manual_seed(42)\n",
        "\n",
        "\n",
        "    prompts = [og_cap]\n",
        "    controller = AttentionStore()\n",
        "\n",
        "    original_image, x_t = run_and_display(\n",
        "        prompts,\n",
        "        controller,\n",
        "        latent=None,\n",
        "        run_baseline=False,\n",
        "        generator=g_cpu\n",
        "    )\n",
        "\n",
        "    original_pil = Image.fromarray(original_image[0])\n",
        "\n",
        "    original_pil = resize(original_pil, (new_h, new_w))\n",
        "    original_pil = original_pil.resize(target_resolution, Image.LANCZOS)\n",
        "\n",
        "    for instr, ec in edited_caps:\n",
        "        prompts = [og_cap, ec]\n",
        "        controller = AttentionRefine(\n",
        "            prompts,\n",
        "            NUM_DIFFUSION_STEPS,\n",
        "            cross_replace_steps=1.0,\n",
        "            self_replace_steps=0.6\n",
        "        )\n",
        "\n",
        "        edited_image, _ = run_and_display(\n",
        "            prompts,\n",
        "            controller,\n",
        "            latent=x_t,\n",
        "            generator=g_cpu\n",
        "        )\n",
        "\n",
        "        edited_pil = Image.fromarray(edited_image[1])\n",
        "\n",
        "        edited_pil = resize(edited_pil, (new_h, new_w))\n",
        "        edited_pil = edited_pil.resize(target_resolution, Image.LANCZOS)\n",
        "\n",
        "        sample_dir = os.path.join(save_root, f\"sample_{sample_idx:04d}\")\n",
        "        os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "        original_pil.save(os.path.join(sample_dir, \"original.png\"))\n",
        "        edited_pil.save(os.path.join(sample_dir, \"edited.png\"))\n",
        "\n",
        "        with open(os.path.join(sample_dir, \"original_caption.txt\"), 'w') as f:\n",
        "            f.write(og_cap)\n",
        "\n",
        "        with open(os.path.join(sample_dir, \"edited_caption.txt\"), 'w') as f:\n",
        "            f.write(ec)\n",
        "\n",
        "        with open(os.path.join(sample_dir, \"instruction.txt\"), 'w') as f:\n",
        "            f.write(instr)\n",
        "\n",
        "        sample_idx += 1\n",
        "\n",
        "        # Remove the break below if you want to run all edit instructions\n",
        "        break\n",
        "\n",
        "    # Remove the break below if you want to run on all input captions\n",
        "    break\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00850f16d0934d63a3b988d3d261dec2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01beb93790ea4a49ae2253da5bd6aaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad0574ba2104a9b99efc97fb94ab604",
            "placeholder": "​",
            "style": "IPY_MODEL_2f2871256f634e2aa8850b582504aa25",
            "value": " 7/7 [00:02&lt;00:00,  3.57it/s]"
          }
        },
        "031afc1c05dd4080898d402d97748c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035a2bcd3ffe43ecb8679ef2d06db2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087339a206cc4a23a2da89908e8cb717": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092dab7c69b040a5a97656f000e7bcdc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09a99cc507a04385bdd2285cf3afe72e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24ac4a27c846462c81394845960543da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "289ed9e039334a63a29578d54e408b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c40b2bcb15d348ea8f904bf6d19d0b1b",
              "IPY_MODEL_e5c23ce424bb48e8a30bd93f4c109524",
              "IPY_MODEL_f8f3a6cce09a4f88bf0a543e11276610"
            ],
            "layout": "IPY_MODEL_4fe65fa5c87146eb891bb981700433bf"
          }
        },
        "28ecb263b8664bfe9f1988d3aa352082": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bbdb71798b74e9ca5dfab251df05a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf12cefd733492ca68b89f908a95f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c425438c366d48c4988d019cb41e9afc",
            "placeholder": "​",
            "style": "IPY_MODEL_e4132c0b523d442e841e763838f76115",
            "value": " 51/51 [00:25&lt;00:00,  1.98it/s]"
          }
        },
        "2f2871256f634e2aa8850b582504aa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "328393d5de84442dbece09ae627e1be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00850f16d0934d63a3b988d3d261dec2",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1f38831492d4f77bcc39cf16a4cb878",
            "value": 16
          }
        },
        "3d9cd571c6654ac289cccdfe13fcf1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fa086f7175d4bd19ba459643dc23354": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41156a3a61fc4e92952f224bb7c566ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418b345cec1349e7b8427d3456974f31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b207d215705d45318a49da033a733642",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d9cd571c6654ac289cccdfe13fcf1b5",
            "value": 51
          }
        },
        "43b4cdda4a8443efa2260e29dc579a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9010bbb959f349268d7c0bf012293641",
              "IPY_MODEL_e0292ea84ff5485d921eef6cd387fb5b",
              "IPY_MODEL_e5c5bb0f21624ea084a6b987d9e4bd23"
            ],
            "layout": "IPY_MODEL_899aadafb12348aea5bb83094786763a"
          }
        },
        "4b37efa16725442aa949962c1afe5524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c69674a607734d0186f19a6aa8ffc034",
              "IPY_MODEL_328393d5de84442dbece09ae627e1be1",
              "IPY_MODEL_fa5cdd80763d4f5a869b0f1722c0f8ac"
            ],
            "layout": "IPY_MODEL_035a2bcd3ffe43ecb8679ef2d06db2d4"
          }
        },
        "4dc5f9ff6d924d76806b7b559d058a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fe65fa5c87146eb891bb981700433bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "574c7bab5a724c15b21e0ec71b4b452b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615f7c39bc554ac29cc1988b808284a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7092d722fd684f859ec7c25c04ecd84a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77704e8ba56048edb8fe7496dd8f8c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4a4ad095424c25a98862cfb99ae420",
            "placeholder": "​",
            "style": "IPY_MODEL_a336b9cbd16a4b399edc4708cd0a898a",
            "value": " 51/51 [00:49&lt;00:00,  1.02it/s]"
          }
        },
        "781b5664894f48d694f3c181000290d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5f85218f7c147dc99fd3accedaeb087",
              "IPY_MODEL_f5b26d9383fd455db669afca8c4a318f",
              "IPY_MODEL_77704e8ba56048edb8fe7496dd8f8c11"
            ],
            "layout": "IPY_MODEL_81b08039964948c6a61eb85c85a4005d"
          }
        },
        "8054c7299f67463287f7b517ba46fb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09a99cc507a04385bdd2285cf3afe72e",
            "placeholder": "​",
            "style": "IPY_MODEL_f801fb50a0e04e6f9b646141bb333e39",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "81b08039964948c6a61eb85c85a4005d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87fc453ff88d47b59f8d99a312e79543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "899aadafb12348aea5bb83094786763a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b377f944b334f96bec7aa619849d964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8054c7299f67463287f7b517ba46fb20",
              "IPY_MODEL_b195d25c62024da39f4587ba11e933a2",
              "IPY_MODEL_01beb93790ea4a49ae2253da5bd6aaad"
            ],
            "layout": "IPY_MODEL_28ecb263b8664bfe9f1988d3aa352082"
          }
        },
        "9010bbb959f349268d7c0bf012293641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9263865e504ee286bbe49d28a07df8",
            "placeholder": "​",
            "style": "IPY_MODEL_87fc453ff88d47b59f8d99a312e79543",
            "value": "100%"
          }
        },
        "92050fd669e0434097133cb4906c1e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a336b9cbd16a4b399edc4708cd0a898a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4a4ad095424c25a98862cfb99ae420": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb0e3d1b91647e3be1ecdfd539cb678": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af70071ba040433ca790cd15c38f3395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0787b4e557049a1bb959405b88a9a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b195d25c62024da39f4587ba11e933a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7092d722fd684f859ec7c25c04ecd84a",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f735a1a9e86d4d659bfedeb53fe16569",
            "value": 7
          }
        },
        "b207d215705d45318a49da033a733642": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f85218f7c147dc99fd3accedaeb087": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574c7bab5a724c15b21e0ec71b4b452b",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b9f24006b849feb718ae4bb810e0a6",
            "value": "100%"
          }
        },
        "bad0574ba2104a9b99efc97fb94ab604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf681b0268894ee3ab9d6ca33e5bd442": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40b2bcb15d348ea8f904bf6d19d0b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087339a206cc4a23a2da89908e8cb717",
            "placeholder": "​",
            "style": "IPY_MODEL_f311c13fb8d7486c97a7d10c11834a87",
            "value": "100%"
          }
        },
        "c425438c366d48c4988d019cb41e9afc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69674a607734d0186f19a6aa8ffc034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76ffc21d3174ca4bf872b2b9ac90453",
            "placeholder": "​",
            "style": "IPY_MODEL_b0787b4e557049a1bb959405b88a9a28",
            "value": "Fetching 16 files: 100%"
          }
        },
        "c76ffc21d3174ca4bf872b2b9ac90453": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b9f24006b849feb718ae4bb810e0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c92a2647c77d4733ba099128efa9e02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb31eb583b7e43578eec2bf9ab5d935f",
              "IPY_MODEL_418b345cec1349e7b8427d3456974f31",
              "IPY_MODEL_2bf12cefd733492ca68b89f908a95f10"
            ],
            "layout": "IPY_MODEL_24ac4a27c846462c81394845960543da"
          }
        },
        "cb31eb583b7e43578eec2bf9ab5d935f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af70071ba040433ca790cd15c38f3395",
            "placeholder": "​",
            "style": "IPY_MODEL_92050fd669e0434097133cb4906c1e0d",
            "value": "100%"
          }
        },
        "d1f38831492d4f77bcc39cf16a4cb878": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de9263865e504ee286bbe49d28a07df8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0292ea84ff5485d921eef6cd387fb5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa55f2eb11fa49cda1ba1f39a3698800",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adb0e3d1b91647e3be1ecdfd539cb678",
            "value": 51
          }
        },
        "e4132c0b523d442e841e763838f76115": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5c23ce424bb48e8a30bd93f4c109524": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41156a3a61fc4e92952f224bb7c566ab",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4dc5f9ff6d924d76806b7b559d058a97",
            "value": 51
          }
        },
        "e5c5bb0f21624ea084a6b987d9e4bd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_092dab7c69b040a5a97656f000e7bcdc",
            "placeholder": "​",
            "style": "IPY_MODEL_2bbdb71798b74e9ca5dfab251df05a74",
            "value": " 51/51 [00:24&lt;00:00,  2.11it/s]"
          }
        },
        "f311c13fb8d7486c97a7d10c11834a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4e88ec388b646fc9d9cca18179873b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b26d9383fd455db669afca8c4a318f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_031afc1c05dd4080898d402d97748c0d",
            "max": 51,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_615f7c39bc554ac29cc1988b808284a4",
            "value": 51
          }
        },
        "f6a23a134d644989a3156f7159ed305e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f735a1a9e86d4d659bfedeb53fe16569": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f801fb50a0e04e6f9b646141bb333e39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8f3a6cce09a4f88bf0a543e11276610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e88ec388b646fc9d9cca18179873b5",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa086f7175d4bd19ba459643dc23354",
            "value": " 51/51 [00:46&lt;00:00,  1.06it/s]"
          }
        },
        "fa55f2eb11fa49cda1ba1f39a3698800": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5cdd80763d4f5a869b0f1722c0f8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf681b0268894ee3ab9d6ca33e5bd442",
            "placeholder": "​",
            "style": "IPY_MODEL_f6a23a134d644989a3156f7159ed305e",
            "value": " 16/16 [00:26&lt;00:00,  1.89s/it]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
