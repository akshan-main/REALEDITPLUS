{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.11/site-packages (4.51.3)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.11/site-packages (10.2.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (4.65.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nblip2_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\\nblip2_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\").to(device)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install transformers pillow pandas tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "#from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def ensure_direct_image_url(url):\n",
    "    \"\"\"\n",
    "    For imgur: convert non-direct to i.imgur.com/ID.jpg.\n",
    "    All other URLs: return as-is.\n",
    "    \"\"\"\n",
    "    if \"imgur.com\" in url and not re.search(r'\\.(jpg|jpeg|png|gif|bmp|webp|tiff)$', url, re.IGNORECASE):\n",
    "        match = re.search(r'imgur\\.com/(?:gallery/|a/)?([^/?#]+)', url)\n",
    "        if match:\n",
    "            img_id = match.group(1)\n",
    "            return f\"https://i.imgur.com/{img_id}.jpg\"\n",
    "        match = re.search(r'imgur\\.com/([^/?#]+)', url)\n",
    "        if match:\n",
    "            img_id = match.group(1)\n",
    "            return f\"https://i.imgur.com/{img_id}.jpg\"\n",
    "    return url\n",
    "\n",
    "#your logic\n",
    "def smart_download_image(url, save_path):\n",
    "    if \"dropbox.com\" in url:\n",
    "        url = url.replace(\"?dl=0\", \"\")\n",
    "        if \"?raw=1\" not in url:\n",
    "            if \"?\" in url:\n",
    "                url += \"&raw=1\"\n",
    "            else:\n",
    "                url += \"?raw=1\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8\",\n",
    "        \"Referer\": url,\n",
    "        \"Accept-Encoding\": \"identity\",\n",
    "        \"Connection\": \"keep-alive\"\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, timeout=30)\n",
    "        if resp.status_code == 200 and resp.headers.get('content-type', '').startswith(\"image\"):\n",
    "            with open(save_path, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed (status {resp.status_code}, type {resp.headers.get('content-type', '')}) for {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download error for {url}: {e}\")\n",
    "    return False\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
    "\"\"\"\n",
    "blip2_processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-flan-t5-xl\")\n",
    "blip2_model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-flan-t5-xl\").to(device)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:00<00:00,  6.06s/it]\n"
     ]
    }
   ],
   "source": [
    "def generate_blip_caption(image_path, blip_processor, blip_model):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = blip_processor(images=image, return_tensors=\"pt\").to(blip_model.device)\n",
    "        output = blip_model.generate(**inputs, max_length=50, num_beams=11,length_penalty=1.7, repetition_penalty=1.4,early_stopping=True, do_sample=False)\n",
    "        caption = blip_processor.decode(output[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        print(f\"BLIP failed for {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\"\"\"\n",
    "def generate_blip2_flan_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    prompt = \"Describe this image in extreme detail:\"\n",
    "    inputs = blip2_processor(images=image, text=prompt, return_tensors=\"pt\").to(device)\n",
    "    output = blip2_model.generate(**inputs, max_new_tokens=35)\n",
    "    caption = blip2_processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_csv(\"RealEdit_train_split_urls.csv\")\n",
    "\n",
    "output = []\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "N = 10\n",
    "for i, row in tqdm(df.iterrows(), total=min(len(df), N)):\n",
    "    if i >= N: break\n",
    "    orig_url = str(row[\"input_url\"])\n",
    "    img_url = ensure_direct_image_url(orig_url)\n",
    "    img_name = row[\"input_image_name\"]\n",
    "    edit_request = row['instruction']\n",
    "    local_path = f\"images/{img_name}\"\n",
    "    caption = \"\"\n",
    "    if smart_download_image(img_url, local_path):\n",
    "        caption = generate_blip_caption(local_path, blip_processor, blip_model)\n",
    "        #caption = generate_blip2_flan_caption(local_path)\n",
    "    if 'is no longer available' in caption:\n",
    "        os.remove(local_path)\n",
    "        continue\n",
    "    output.append({\n",
    "        \"input_image_name\": img_name,\n",
    "        \"input_url\": orig_url,\n",
    "        \"download_url\": img_url,\n",
    "        \"download_success\": os.path.exists(local_path) and os.path.getsize(local_path) > 0,\n",
    "        \"caption\": caption,\n",
    "        \"edit_request\": edit_request\n",
    "    })\n",
    "\n",
    "ff = pd.DataFrame(output)\n",
    "\n",
    "ff.to_csv(\"captions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW RESPONSE:\n",
      " [\n",
      "  \"Enhance the lighting and contrast of the image.\",\n",
      "  \"Remove any distracting background elements.\",\n",
      "  \"Apply a vintage filter to give the image a nostalgic feel.\",\n",
      "  \"Add a soft focus effect to create a dreamy atmosphere.\",\n",
      "  \"Crop the image to focus on the man and woman taking the selfie.\"\n",
      "]\n",
      "RAW RESPONSE:\n",
      " [\n",
      "  \"Convert the image to black and white for a vintage look.\",\n",
      "  \"Crop the image to focus on the man and child, emphasizing the bond between them.\",\n",
      "  \"Apply a sepia tone filter to give the photo an antique feel.\",\n",
      "  \"Add a soft light overlay to create a dreamy atmosphere.\",\n",
      "  \"Adjust the color balance to bring out the warm tones in the photo.\"\n",
      "]\n",
      "RAW RESPONSE:\n",
      " [\n",
      "  \"Add a vintage sepia tone effect to give the image a nostalgic feel.\",\n",
      "  \"Enhance the contrast to make the shadows and highlights more dramatic.\",\n",
      "  \"Apply a grainy texture overlay to create a weathered, aged look.\",\n",
      "  \"Convert the image to a high contrast black and white to make the subject stand out.\",\n",
      "  \"Add a subtle vignette effect to draw focus towards the man in the center.\"\n",
      "]\n",
      "RAW RESPONSE:\n",
      " ```json\n",
      "[\n",
      "    \"Apply a vintage filter to give the photo an aged look.\",\n",
      "    \"Enhance the clarity and sharpness of the image to make the people and house details stand out.\",\n",
      "    \"Crop the image to focus on the group of people and the house, removing any distracting background.\",\n",
      "    \"Add a sepia tone to evoke a nostalgic feel in the photo.\",\n",
      "    \"Remove any scratches or blemishes from the old photo to restore its original quality.\"\n",
      "]\n",
      "```\n",
      "RAW RESPONSE:\n",
      " ```json\n",
      "[\n",
      "    \"Enhance the contrast to make the black and white tones pop.\",\n",
      "    \"Apply a vintage filter to give the image an aged look.\",\n",
      "    \"Crop out distractions in the background to focus on the group of people.\",\n",
      "    \"Add a subtle vignette effect to draw attention to the center of the image.\",\n",
      "    \"Convert the image to sepia tone for a classic feel.\"\n",
      "]\n",
      "```\n",
      "RAW RESPONSE:\n",
      " ```json\n",
      "[\n",
      "    \"Convert the image to black and white.\",\n",
      "    \"Enhance the contrast to make the image more dynamic.\",\n",
      "    \"Blur the background to make the subjects stand out.\",\n",
      "    \"Add a vintage film grain effect to give the photo an aged look.\",\n",
      "    \"Crop the image to focus on the man and the little girl.\"\n",
      "]\n",
      "```\n",
      "RAW RESPONSE:\n",
      " ```json\n",
      "[\n",
      "    \"Enhance the color saturation to make the image more vibrant.\",\n",
      "    \"Apply a vintage filter to give the photo an aged look.\",\n",
      "    \"Crop the image to focus more on the two people standing on the beach.\",\n",
      "    \"Add a subtle sepia tone to the image for a nostalgic effect.\",\n",
      "    \"Remove any scratches or blemishes from the old photo to improve its quality.\"\n",
      "]\n",
      "```\n",
      "RAW RESPONSE:\n",
      " [\n",
      "    \"Apply a vintage filter to give the image an aged look.\",\n",
      "    \"Add a dramatic black and white effect to enhance the contrast.\",\n",
      "    \"Blur the background to focus the viewer's attention on the man and child.\",\n",
      "    \"Convert the guns into harmless objects like toys or flowers.\",\n",
      "    \"Crop the image to create a more intimate composition between the man and child.\"\n",
      "]\n",
      "RAW RESPONSE:\n",
      " [\n",
      "    \"Colorize this black and white photo.\",\n",
      "    \"Enhance the contrast of the image.\",\n",
      "    \"Add a vintage sepia tone to the photo.\",\n",
      "    \"Remove scratches and dust particles from the image.\",\n",
      "    \"Apply a soft focus effect to create a dreamy atmosphere.\"\n",
      "]\n",
      "3v1cvp.jpg:\n",
      "  1. Enhance the lighting and contrast of the image.\n",
      "  2. Remove any distracting background elements.\n",
      "  3. Apply a vintage filter to give the image a nostalgic feel.\n",
      "  4. Add a soft focus effect to create a dreamy atmosphere.\n",
      "  5. Crop the image to focus on the man and woman taking the selfie.\n",
      "\n",
      "3v2ru0.jpeg:\n",
      "  1. Convert the image to black and white for a vintage look.\n",
      "  2. Crop the image to focus on the man and child, emphasizing the bond between them.\n",
      "  3. Apply a sepia tone filter to give the photo an antique feel.\n",
      "  4. Add a soft light overlay to create a dreamy atmosphere.\n",
      "  5. Adjust the color balance to bring out the warm tones in the photo.\n",
      "\n",
      "3vg97p.jpg:\n",
      "  1. Add a vintage sepia tone effect to give the image a nostalgic feel.\n",
      "  2. Enhance the contrast to make the shadows and highlights more dramatic.\n",
      "  3. Apply a grainy texture overlay to create a weathered, aged look.\n",
      "  4. Convert the image to a high contrast black and white to make the subject stand out.\n",
      "  5. Add a subtle vignette effect to draw focus towards the man in the center.\n",
      "\n",
      "3vo49o.jpg:\n",
      "  1. Apply a vintage filter to give the photo an aged look.\n",
      "  2. Enhance the clarity and sharpness of the image to make the people and house details stand out.\n",
      "  3. Crop the image to focus on the group of people and the house, removing any distracting background.\n",
      "  4. Add a sepia tone to evoke a nostalgic feel in the photo.\n",
      "  5. Remove any scratches or blemishes from the old photo to restore its original quality.\n",
      "\n",
      "3vo9iy.jpg:\n",
      "  1. Enhance the contrast to make the black and white tones pop.\n",
      "  2. Apply a vintage filter to give the image an aged look.\n",
      "  3. Crop out distractions in the background to focus on the group of people.\n",
      "  4. Add a subtle vignette effect to draw attention to the center of the image.\n",
      "  5. Convert the image to sepia tone for a classic feel.\n",
      "\n",
      "3vqxg7.jpeg:\n",
      "  1. Convert the image to black and white.\n",
      "  2. Enhance the contrast to make the image more dynamic.\n",
      "  3. Blur the background to make the subjects stand out.\n",
      "  4. Add a vintage film grain effect to give the photo an aged look.\n",
      "  5. Crop the image to focus on the man and the little girl.\n",
      "\n",
      "3vtbmy.jpg:\n",
      "  1. Enhance the color saturation to make the image more vibrant.\n",
      "  2. Apply a vintage filter to give the photo an aged look.\n",
      "  3. Crop the image to focus more on the two people standing on the beach.\n",
      "  4. Add a subtle sepia tone to the image for a nostalgic effect.\n",
      "  5. Remove any scratches or blemishes from the old photo to improve its quality.\n",
      "\n",
      "3vtoea.jpeg:\n",
      "  1. Apply a vintage filter to give the image an aged look.\n",
      "  2. Add a dramatic black and white effect to enhance the contrast.\n",
      "  3. Blur the background to focus the viewer's attention on the man and child.\n",
      "  4. Convert the guns into harmless objects like toys or flowers.\n",
      "  5. Crop the image to create a more intimate composition between the man and child.\n",
      "\n",
      "3vupca.jpeg:\n",
      "  1. Colorize this black and white photo.\n",
      "  2. Enhance the contrast of the image.\n",
      "  3. Add a vintage sepia tone to the photo.\n",
      "  4. Remove scratches and dust particles from the image.\n",
      "  5. Apply a soft focus effect to create a dreamy atmosphere.\n",
      "\n",
      "3v1cvp.jpg:\n",
      "  1. This is an enhanced image of a man and woman taking a selfie, with improved lighting and contrast.\n",
      "  2. This is an image of a man and woman taking a selfie with distracting background elements removed.\n",
      "  3. This is a vintage-filtered image of a man and woman capturing a nostalgic moment in a selfie.\n",
      "  4. This is an image of a man and woman taking a selfie with a soft focus effect, creating a dreamy atmosphere.\n",
      "  5. This is a cropped image of a man and woman taking a selfie.\n",
      "\n",
      "3v2ru0.jpeg:\n",
      "  1. This is a black and white photo of a man and two women and a child, giving it a vintage look.\n",
      "  2. Edited caption: 'Crop to highlight the bond between the man and child in this old photo.'\n",
      "  3. This is an old photo of a man, two women, and a child with a sepia tone filter applied, adding an antique feel to the image.\n",
      "  4. This is an old photo of a man, two women, and a child, enveloped in a soft light overlay that creates a dreamy atmosphere.\n",
      "  5. This is an old photo of a man, two women, and a child with enhanced warm tones to create a cozy and nostalgic feel.\n",
      "\n",
      "3vg97p.jpg:\n",
      "  1. This is a black and white photo of a man standing in a warehouse with a vintage sepia tone effect that gives the image a nostalgic feel.\n",
      "  2. This is a black and white photo of a man standing in a warehouse with enhanced contrast, creating more dramatic shadows and highlights.\n",
      "  3. This is a black and white photo of a man standing in a warehouse, enhanced with a grainy texture overlay to give it a weathered, aged look.\n",
      "  4. This is a high contrast black and white photo of a man standing in a warehouse, emphasizing the subject's presence.\n",
      "  5. This is a black and white photo of a man standing in a warehouse, enhanced with a subtle vignette effect that draws focus towards the man in the center.\n",
      "\n",
      "3vo49o.jpg:\n",
      "  1. This is an old photo of a group of people standing in front of a house, enhanced with a vintage filter for a beautifully aged look.\n",
      "  2. Enhanced the clarity and sharpness of this old photo to make the group of people and house details stand out vividly.\n",
      "  3. This is an old photo of a group of people standing in front of a house, with the distracting background cropped out to highlight the group and the house.\n",
      "  4. This is an old photo of a group of people standing in front of a house, with a sepia tone added to evoke a nostalgic feel.\n",
      "  5. 'Restored old photo of a group of people standing in front of a house, now free of scratches and blemishes.'\n",
      "\n",
      "3vo9iy.jpg:\n",
      "  1. Enhanced black and white photograph of a large group of people posing for a picture, with intensified contrast to make the tones stand out.\n",
      "  2. 'Vintage black and white photograph of a large group of people posing for a picture, with an aged filter giving it a nostalgic feel.'\n",
      "  3. 'Black and white photograph of a large group of people posing for a picture, with distractions in the background cropped out to highlight the group.'\n",
      "  4. 'Black and white photograph of a large group of people posing for a picture with a subtle vignette effect enhancing the focus on the center of the image.'\n",
      "  5. Sepia-toned photograph of a large group of people posing for a picture, exuding a classic and timeless vibe.\n",
      "\n",
      "3vqxg7.jpeg:\n",
      "  1. The image has been converted to black and white, showing a man holding a little girl.\n",
      "  2. The black and white photo of a man holding a little girl is enhanced with increased contrast, adding a dynamic touch to the image.\n",
      "  3. In the black and white photo, a man holds a little girl, with the background blurred to emphasize the subjects.\n",
      "  4. The black and white photo of a man holding a little girl is enhanced with a vintage film grain effect, giving it an aged and nostalgic appearance.\n",
      "  5. In the cropped image, a man tenderly holds a little girl.\n",
      "\n",
      "3vtbmy.jpg:\n",
      "  1. Enhanced color saturation brings out the vibrancy of this old photo, showing two people standing on the beach.\n",
      "  2. This is an old photo of two people standing on the beach with a vintage filter applied to give it an aged look.\n",
      "  3. 'Crop the image to highlight the two people standing on the beach in this old photo.'\n",
      "  4. This is an old photo of two people standing on the beach with a subtle sepia tone added for a nostalgic effect.\n",
      "  5. This is an enhanced version of an old photo showing two people standing on the beach, now free of scratches and blemishes.\n",
      "\n",
      "3vtoea.jpeg:\n",
      "  1. This is a black and white photo of a man and a child with guns, enhanced with a vintage filter for an aged and nostalgic appearance.\n",
      "  2. This is a striking black and white photo of a man and a child with guns, intensified by a dramatic effect that enhances the contrast.\n",
      "  3. In this black and white photo, a man and a child with guns stand out sharply against a blurred background, drawing the viewer's attention to their presence.\n",
      "  4. This is a black and white photo of a man and a child with harmless objects like toys or flowers.\n",
      "  5. This is a cropped black and white photo showing a close and intimate moment between a man and a child with guns.\n",
      "\n",
      "3vupca.jpeg:\n",
      "  1. Colorized version of an old black and white photo showing a group of people.\n",
      "  2. Enhanced the contrast of this old black and white photo featuring a group of people.\n",
      "  3. This is a vintage sepia-toned photo of a group of people.\n",
      "  4. This is a restored black and white photo of a group of people with scratches and dust particles removed.\n",
      "  5. This is an old black and white photo of a group of people with a soft focus effect applied, creating a dreamy atmosphere.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "from typing import List\n",
    "\n",
    "from api_key import OPENAI_API_KEY\n",
    "\n",
    "def generate_edit_instructions(\n",
    "    base_caption: str,\n",
    "    example_request: str,\n",
    "    num_instructions: int,\n",
    "    model: str = \"gpt-3.5-turbo\",\n",
    "    temperature: float = 0.7\n",
    ") -> List[str]:\n",
    "    prompt = (\n",
    "        f\"You are an image editing assistant. Given the image caption: '{base_caption}', \"\n",
    "        f\"generate {num_instructions} concise and diverse edit instructions \"\n",
    "        f\"that could be applied to the image. \"\n",
    "        f\"Use this example edit instruction as a reference: '{example_request}'. \"\n",
    "        f\"Return the instructions as a JSON array of strings.\"\n",
    "    )\n",
    "    client = openai.OpenAI(api_key = OPENAI_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You generate creative image edit instructions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=num_instructions * 25,\n",
    "    )\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    match = re.search(r\"\\[\\s*\\\".*?\\\"\\s*(?:,\\s*\\\".*?\\\"\\s*)*\\]\", content, re.DOTALL)\n",
    "    \n",
    "    #instructions = json.loads(content)\n",
    "    instructions = json.loads(match.group(0))\n",
    "    \n",
    "    if not isinstance(instructions, list):\n",
    "        raise ValueError(\"Parsed JSON is not list\")\n",
    "    return instructions\n",
    "\n",
    "def generate_edited_caption(\n",
    "    base_caption: str,\n",
    "    edit_request: str,\n",
    "    model: str = \"gpt-3.5-turbo\",\n",
    "    temperature: float = 0.3\n",
    ") -> str:\n",
    "    prompt = (\n",
    "        f\"Original caption: '{base_caption}'\\n\"\n",
    "        f\"Edit request: '{edit_request}'\\n\"\n",
    "        f\"Write an edited image caption around the same length as the original, but with the edit request incorporated into it.\"\n",
    "    )\n",
    "    client = openai.OpenAI(api_key = OPENAI_API_KEY)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You summarize image edits as text instructions.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=60,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "\n",
    "img_to_edit_req = {}\n",
    "img_to_new_cap = {}\n",
    "\n",
    "for i, row in ff.iterrows():\n",
    "    caption = row['caption']\n",
    "    example_request = row['edit_request']\n",
    "    img_name = row['input_image_name']\n",
    "    img_to_edit_req[img_name] = list(generate_edit_instructions(caption, example_request, 5))\n",
    "    img_to_new_cap[img_name] = list(generate_edited_caption(caption, img_to_edit_req[img_name][x]) for x in range(5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for img_name, edits in img_to_edit_req.items():\n",
    "    print(f\"{img_name}:\")\n",
    "    for i, edit in enumerate(edits, 1):\n",
    "        print(f\"  {i}. {edit}\")\n",
    "    print()\n",
    "\n",
    "for img_name, edits in img_to_new_cap.items():\n",
    "    print(f\"{img_name}:\")\n",
    "    for i, edit in enumerate(edits, 1):\n",
    "        print(f\"  {i}. {edit}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "#generate_edit_instructions(caption, example_request, 5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of a man and woman taking a selfie with enhanced vibrant colors.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
